

---

# ğŸ“˜ **Customer Churn Prediction Notebook**

This repository contains a **Jupyter Notebook** project that builds a **Customer Churn Prediction System** using the **Telco Customer Churn Dataset**. The focus is on visual exploration, explainability, and comparison of baseline vs production-grade ML pipelines.

---

## ğŸ“‚ **Project Notebook**

**Notebook file:**

```
Customer_Churn_Prediction.ipynb
```

The notebook walks through the entire lifecycle of the churn prediction workflow.

---

## ğŸ¯ **Goal of the Project**

Churn prediction helps telecom & subscription businesses:

* Identify customers likely to churn
* Reduce revenue loss
* Improve customer retention
* Optimize customer lifetime value (CLV)

This notebook demonstrates how churn can be modeled using real-world ML techniques.

---

## ğŸ§° **Dataset Used**

Dataset: **Telco Customer Churn (IBM)**
Target column: **Churn (Yes/No)**

Core feature domains:

* **Customer Demographics**
* **Service Subscriptions**
* **Contract & Billing Details**
* **Monthly/Total Charges**
* **Tenure**

---

## ğŸ” **Exploratory Data Analysis (EDA)**

The notebook includes visual analysis:

âœ” Churn class imbalance
âœ” Tenure distribution + churn relationship
âœ” Monthly charges vs churn
âœ” Contract patterns
âœ” Paperless billing analysis

Goal: understand **drivers of churn** before modeling.

---

## ğŸ§ª **Modeling Approach**

The project uses a **two-phase training strategy**:

### **Phase 1 â€” Baseline Model**

* Logistic Regression
* No scaling
* No encoding pipelines
* No imbalance handling

Purpose: establish a benchmark

---

### **Phase 2 â€” Professional Model**

Improved pipeline including:

âœ” One-Hot Encoding (Categorical)
âœ” Standard Scaling (Numerical)
âœ” Class imbalance handled via **SMOTE**
âœ” Model used: **XGBoost**

This reflects real industry churn modeling workflows.

---

## ğŸ“Š **Evaluation Metrics**

Models compared using:

* **Accuracy**
* **Precision**
* **Recall**
* **F1 Score**

Output plots include:

ğŸ“ˆ **Side-by-side performance comparison**
ğŸ§  **Feature Importance (XGBoost)**
ğŸ“‰ **Confusion Matrix**
ğŸ“‘ **Classification Report**

---

## ğŸ§  **Key Business Insights**

From feature importance:

* **Month-to-Month contracts** show highest churn
* **Paperless Billing customers** churn more often
* **Tech support reduces churn**
* **Short-tenure customers** have high churn risk
* **Higher Monthly Charges** correlates with churn

These insights can drive retention strategies.

---

## ğŸ›  **Tech Stack**

**Notebook environment:**
âœ” Jupyter / VS Code / Colab

**Libraries used:**

```
pandas
numpy
matplotlib
seaborn
scikit-learn
imbalanced-learn
xgboost
```

---

## ğŸš€ **How to Run the Notebook**

1ï¸âƒ£ Clone or download this repo
2ï¸âƒ£ Install dependencies:

```
pip install -r requirements.txt
```

3ï¸âƒ£ Open the notebook:

```
jupyter notebook Customer_Churn_Prediction.ipynb
```

(or open directly in **VS Code** using Jupyter extension)

---

## ğŸ **Results Summary**

The professional pipeline improved performance, especially on **Recall**, which is critical for churn use cases (better to identify churn-risk customers even at slight precision cost).

---

